{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2\n",
    "\n",
    "DATASETS\n",
    "\n",
    "for our methods overcluster with 15 clusters:\n",
    "\n",
    "- Gaussians with 6 clusters in 8D, 16D, 32D, 64D\n",
    "- Gaussians with 6 clusters with vaying frequency in 8D, 16D, 32D, 64D\n",
    "- Worms with 6 clusters in 8D, 16D, 32D, 64D\n",
    "- funky shapes with 6 clusters in 8D, 16D, 32D, 64D\n",
    "- transcriptomic dataset (one mentioned in PAGA paper)\n",
    "\n",
    "after decide on ~4-5 datasets for main figure, rest in Appendix\n",
    "\n",
    "METHODS\n",
    "\n",
    "- K-Means\n",
    "- GMM\n",
    "- TMM\n",
    "- Leiden\n",
    "- Agglomerative + dendrogram\n",
    "- HDBSCAN\n",
    "- Leiden + PAGA\n",
    "- GMM + NEB\n",
    "- GMM + dip-statistic\n",
    "- TMM + NEB\n",
    "- TMM + dip-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corc.graph_metrics import paga, gwg, gwgmara\n",
    "from corc import generation, complex_datasets\n",
    "\n",
    "import densired\n",
    "\n",
    "from openTSNE import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "class Leiden():\n",
    "    def __init__(self, resolution=1.0, seed=42):\n",
    "        self.resolution = resolution\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        counts = csr_matrix(self.data, dtype=np.float32)\n",
    "        adata = ad.AnnData(counts)\n",
    "\n",
    "        self.adata = adata\n",
    "\n",
    "        sc.pp.neighbors(self.adata)\n",
    "        sc.tl.leiden(self.adata, flavor=\"igraph\", n_iterations=2, resolution=self.resolution, random_state=self.seed)\n",
    "\n",
    "        self.labels_ = self.adata.obs['leiden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import studenttmixture\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "# ============\n",
    "n_samples = 1000\n",
    "seed = 30\n",
    "\n",
    "dims = [8,16,32,64]\n",
    "std = 0.075\n",
    "# Gaussians with 6 clusters in 8D, 16D, 32D, 64D\n",
    "blobs1_0 = complex_datasets.make_gaussians(dim=dims[0], std=std*np.sqrt(dims[0]), n_samples=n_samples)\n",
    "blobs1_1 = complex_datasets.make_gaussians(dim=dims[1], std=std*np.sqrt(dims[1]), n_samples=n_samples)\n",
    "blobs1_2 = complex_datasets.make_gaussians(dim=dims[2], std=std*np.sqrt(dims[2]), n_samples=n_samples)\n",
    "blobs1_3 = complex_datasets.make_gaussians(dim=dims[3], std=std*np.sqrt(dims[3]), n_samples=n_samples)\n",
    "\n",
    "# Gaussians with 6 clusters with varying frequency in 8D, 16D, 32D, 64D\n",
    "blobs2_0 = complex_datasets.make_gaussians(dim=dims[0], std=std*np.sqrt(dims[0]), n_samples=n_samples, equal_sized_clusters=False)\n",
    "blobs2_1 = complex_datasets.make_gaussians(dim=dims[1], std=std*np.sqrt(dims[1]), n_samples=n_samples, equal_sized_clusters=False)\n",
    "blobs2_2 = complex_datasets.make_gaussians(dim=dims[2], std=std*np.sqrt(dims[2]), n_samples=n_samples, equal_sized_clusters=False)\n",
    "blobs2_3 = complex_datasets.make_gaussians(dim=dims[3], std=std*np.sqrt(dims[3]), n_samples=n_samples, equal_sized_clusters=False)\n",
    "\n",
    "# Worms with 6 clusters in 8D, 16D, 32D, 64D\n",
    "\n",
    "# funky shapes with 6 clusters in 8D, 16D, 32D, 64D\n",
    "densired0 = complex_datasets.make_densired(dim=dims[0], n_samples=n_samples, std=std*np.sqrt(dims[0]))\n",
    "densired1 = complex_datasets.make_densired(dim=dims[1], n_samples=n_samples, std=std*np.sqrt(dims[1]))\n",
    "densired2 = complex_datasets.make_densired(dim=dims[2], n_samples=n_samples, std=std*np.sqrt(dims[2]))\n",
    "densired3 = complex_datasets.make_densired(dim=dims[3], n_samples=n_samples, std=std*np.sqrt(dims[3]))\n",
    "\n",
    "# MNIST-Nd\n",
    "mnist0 = complex_datasets.make_mnist_nd(dim=dims[0])\n",
    "mnist1 = complex_datasets.make_mnist_nd(dim=dims[1])\n",
    "mnist2 = complex_datasets.make_mnist_nd(dim=dims[2])\n",
    "mnist3 = complex_datasets.make_mnist_nd(dim=dims[3])\n",
    "\n",
    "# transcriptomic dataset (one mentioned in PAGA paper)\n",
    "# paul15 = make_Paul15()\n",
    "\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 13 * 2))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {\n",
    "    \"dim\": 2, \n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 6,\n",
    "    \"n_components\": 15,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "    \"allow_single_cluster\": True,\n",
    "    \"hdbscan_min_cluster_size\": 15,\n",
    "    \"hdbscan_min_samples\": 3,\n",
    "    \"random_state\": 42,\n",
    "    \"resolution\":1.0,\n",
    "    \"resolution_leiden\":1.0,\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    (blobs1_0, {\n",
    "        \"dim\":dims[0], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs1_1, {\n",
    "        \"dim\":dims[1], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs1_2, {\n",
    "        \"dim\":dims[2], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs1_3, {\n",
    "        \"dim\":dims[3], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs2_0, {\n",
    "        \"dim\":dims[0], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs2_1, {\n",
    "        \"dim\":dims[1], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs2_2, {\n",
    "        \"dim\":dims[2], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (blobs2_3, {\n",
    "        \"dim\":dims[3], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (densired0, {\n",
    "        \"dim\":dims[0], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (densired1, {\n",
    "        \"dim\":dims[1], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (densired2, {\n",
    "        \"dim\":dims[2], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (densired3, {\n",
    "        \"dim\":dims[3], \n",
    "        \"n_clusters\": 6,\n",
    "        \"resolution\":1.0,\n",
    "        \"resolution_leiden\":1.0,\n",
    "    }),\n",
    "    (mnist0, {\n",
    "        \"dim\":dims[0], \n",
    "        \"n_clusters\": 15\n",
    "    }),\n",
    "    (mnist1, {\n",
    "        \"dim\":dims[1], \n",
    "        \"n_clusters\": 15\n",
    "    }),\n",
    "    (mnist2, {\n",
    "        \"dim\":dims[2], \n",
    "        \"n_clusters\": 15\n",
    "    }),\n",
    "    (mnist3, {\n",
    "        \"dim\":dims[3], \n",
    "        \"n_clusters\": 15\n",
    "    }),\n",
    "\n",
    "    # (paul15, {\"dim\":1000, \"n_clusters\": 12, \"n_components\":20}),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "    y = np.array(y, dtype='int')\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # dimensionality reduction for plotting results in 2D\n",
    "    perplexity = 100 if dataset in [\"Paul15\"] else 30\n",
    "    tsne = TSNE(\n",
    "            perplexity=perplexity,\n",
    "            metric='euclidean',\n",
    "            n_jobs=8,\n",
    "            random_state=42,\n",
    "            verbose=False,\n",
    "        )\n",
    "    X2D = tsne.fit(X)\n",
    "\n",
    "    # eps = 2.0\n",
    "    # plotrange_x = np.min(X2D, axis=0)[0] - eps, np.max(X2D, axis=0)[0] + eps\n",
    "    # plotrange_y = np.min(X2D, axis=0)[1] - eps, np.max(X2D, axis=0)[1] + eps\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    "    )\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        random_state=params[\"random_state\"],\n",
    "    )\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters=params[\"n_clusters\"], linkage=\"ward\", connectivity=connectivity\n",
    "    )\n",
    "    spectral = cluster.SpectralClustering(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        eigen_solver=\"arpack\",\n",
    "        affinity=\"nearest_neighbors\",\n",
    "        random_state=params[\"random_state\"],\n",
    "    )\n",
    "    dbscan = cluster.DBSCAN(eps=params[\"eps\"])\n",
    "    hdbscan = cluster.HDBSCAN(\n",
    "        min_samples=params[\"hdbscan_min_samples\"],\n",
    "        min_cluster_size=params[\"hdbscan_min_cluster_size\"],\n",
    "        allow_single_cluster=params[\"allow_single_cluster\"],\n",
    "    )\n",
    "    optics = cluster.OPTICS(\n",
    "        min_samples=params[\"min_samples\"],\n",
    "        xi=params[\"xi\"],\n",
    "        min_cluster_size=params[\"min_cluster_size\"],\n",
    "    )\n",
    "    affinity_propagation = cluster.AffinityPropagation(\n",
    "        damping=params[\"damping\"],\n",
    "        preference=params[\"preference\"],\n",
    "        random_state=params[\"random_state\"],\n",
    "    )\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\",\n",
    "        metric=\"cityblock\",\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        connectivity=connectivity,\n",
    "    )\n",
    "    birch = cluster.Birch(n_clusters=params[\"n_clusters\"])\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=params[\"n_clusters\"],\n",
    "        covariance_type=\"full\",\n",
    "        random_state=params[\"random_state\"],\n",
    "    )\n",
    "    tmm = studenttmixture.EMStudentMixture(\n",
    "        n_components=params[\"n_clusters\"],\n",
    "        n_init=5,\n",
    "        fixed_df=False,#True,\n",
    "        # df=1.0,\n",
    "        init_type=\"k++\",\n",
    "        random_state=params[\"random_state\"]\n",
    "        )\n",
    "    leiden = Leiden(\n",
    "        resolution=params[\"resolution_leiden\"], \n",
    "        seed=params[\"random_state\"]\n",
    "        )\n",
    "    mpaga = paga.PAGA(\n",
    "        latent_dim=params[\"dim\"], \n",
    "        resolution=params[\"resolution\"], \n",
    "        seed=params[\"random_state\"]\n",
    "        )\n",
    "    mgwgmara = gwgmara.GWGMara(\n",
    "        latent_dim=params[\"dim\"], \n",
    "        n_components=params[\"n_components\"], \n",
    "        n_neighbors = params[\"n_neighbors\"],\n",
    "        seed=params[\"random_state\"]\n",
    "        )\n",
    "    mgwg = gwg.GWG(\n",
    "        latent_dim=params[\"dim\"], \n",
    "        n_components=params[\"n_components\"],#params[\"n_clusters\"],\n",
    "        n_neighbors = params[\"n_neighbors\"],\n",
    "        seed=params[\"random_state\"]\n",
    "        )\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        (\"MiniBatch\\nKMeans\", two_means),\n",
    "        (\"Agglomerative\\nClustering\", average_linkage),\n",
    "        (\"HDBSCAN\", hdbscan),\n",
    "        (\"Gaussian\\nMixture\", gmm),\n",
    "        (\"t-Student\\nMixture\", tmm),\n",
    "        (\"Leiden\", leiden),\n",
    "        (\"PAGA\", mpaga),\n",
    "        (\"GWG-dip\", mgwgmara),\n",
    "        (\"GWG-pvalue\", mgwg),\n",
    "        # (\"Affinity\\nPropagation\", affinity_propagation),\n",
    "        # (\"MeanShift\", ms),\n",
    "        # (\"Spectral\\nClustering\", spectral),\n",
    "        # (\"Ward\", ward),\n",
    "        # (\"DBSCAN\", dbscan),\n",
    "        # (\"OPTICS\", optics),\n",
    "        # (\"BIRCH\", birch),\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        t0 = time.time()\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \"\n",
    "                + \"connectivity matrix is [0-9]{1,2}\"\n",
    "                + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"Graph is not fully connected, spectral embedding\"\n",
    "                + \" may not work as expected.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            try:\n",
    "                y_pred = algorithm.predict(X)\n",
    "            except ValueError as e:\n",
    "                y_pred = np.array([0]*len(y))\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms)+1, plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                            \"#add8e6\",\n",
    "                            \"#006400\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(max(y_pred), max(y)) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # add black color for outliers (if any)\n",
    "        colors = np.append(colors, [\"#000000\"])\n",
    "        plt.scatter(X2D[:, 0], X2D[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "        if name in [\"GWG-dip\", \"GWG-pvalue\", \"PAGA\"]:\n",
    "            algorithm.plot_graph(X2D)\n",
    "\n",
    "        # plt.xlim(plotrange_x[0], plotrange_x[1])\n",
    "        # plt.ylim(plotrange_y[0], plotrange_y[1])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        # plt.text(\n",
    "        #     0.99,\n",
    "        #     0.01,\n",
    "        #     (\"%.2fs\" % (t1 - t0)).lstrip(\"0\"),\n",
    "        #     transform=plt.gca().transAxes,\n",
    "        #     size=15,\n",
    "        #     horizontalalignment=\"right\",\n",
    "        # )\n",
    "        plot_num += 1\n",
    "\n",
    "    # plot ground truth\n",
    "    plt.subplot(len(datasets), len(clustering_algorithms)+1, plot_num)\n",
    "    if i_dataset == 0:\n",
    "        plt.title('Ground truth', size=18)\n",
    "    plt.scatter(X2D[:, 0], X2D[:, 1], s=10, color=colors[y])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
