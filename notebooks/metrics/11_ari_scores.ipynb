{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354e483cb20c2141",
   "metadata": {},
   "source": [
    "# ARI scores for the precomputed datasets and clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:45:25.546129Z",
     "start_time": "2024-11-08T12:45:25.466319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92aa4ed2013bddce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:45:29.607928Z",
     "start_time": "2024-11-08T12:45:25.588270Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts')\n",
    "import our_datasets\n",
    "import our_algorithms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from nbformat.sign import algorithms\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581a422bfde2396d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848054Z",
     "start_time": "2024-11-08T12:37:28.861124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blobs1_8',\n",
       " 'blobs1_16',\n",
       " 'blobs1_32',\n",
       " 'blobs1_64',\n",
       " 'blobs2_8',\n",
       " 'blobs2_16',\n",
       " 'blobs2_32',\n",
       " 'blobs2_64',\n",
       " 'densired8',\n",
       " 'densired16',\n",
       " 'densired32',\n",
       " 'densired64',\n",
       " 'mnist8',\n",
       " 'mnist16',\n",
       " 'mnist32',\n",
       " 'mnist64']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = our_datasets.COMPLEX_DATASETS\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaceda969d25ef",
   "metadata": {},
   "source": [
    "our_algorithms.ALGORITHM_SELECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3be76ad3a50446e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848333Z",
     "start_time": "2024-11-08T12:37:29.548016Z"
    }
   },
   "outputs": [],
   "source": [
    "# copied the following list from \"our_algorithms.py\" script\n",
    "algorithms = [\n",
    "    \"MiniBatch\\nKMeans\",\n",
    "    \"Agglomerative\\nClustering\",\n",
    "    \"HDBSCAN\",\n",
    "    \"Gaussian\\nMixture\",\n",
    "    \"t-Student\\nMixture\",\n",
    "    # \"DBSCAN\",\n",
    "    # \"BIRCH\",\n",
    "    # \"OPTICS\",\n",
    "    \"Spectral\\nClustering\",\n",
    "    \"Affinity\\nPropagation\",\n",
    "    \"MeanShift\",\n",
    "    \"Leiden\",\n",
    "    \"PAGA\",\n",
    "    \"Ward\",\n",
    "    # \"Stavia\",\n",
    "    \"GWG-dip\",\n",
    "    \"GWG-pvalue\",\n",
    "    \"TMM-NEB\",\n",
    "    \"GMM-NEB\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498226d18da2c3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848386Z",
     "start_time": "2024-11-08T12:37:29.569687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user/ritzert/git/cluster_vs_continuum/notebooks/metrics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9ef21ef29cb651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848441Z",
     "start_time": "2024-11-08T12:37:29.613746Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_path = \"../../cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e425c3d533ca695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848474Z",
     "start_time": "2024-11-08T12:37:29.636438Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_missing_files(datasets,algorithms, cache_path=\"../../cache\"):\n",
    "    missing_files = []\n",
    "    for dataset_name in datasets:\n",
    "        dataset_filename = f\"{cache_path}/{dataset_name}.pickle\"\n",
    "        if not os.path.exists(dataset_filename):\n",
    "            missing_files.append(dataset_filename)\n",
    "\n",
    "        for algorithm_name in algorithms:\n",
    "            algorithm_name = algorithm_name.replace(\"\\\\n\", \"\\n\").replace(\"\\n\", \"\")\n",
    "            alg_filename = f\"{cache_path}/{dataset_name}_{algorithm_name}.pickle\"\n",
    "            if not os.path.exists(alg_filename):\n",
    "                missing_files.append(alg_filename)\n",
    "    return missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed12213649f3418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T12:43:00.848519Z",
     "start_time": "2024-11-08T12:37:53.394087Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ari_scores(datasets,algorithms, cache_path=\"../../cache\"):\n",
    "    ari_scores = np.zeros((len(datasets),len(algorithms)))\n",
    "    for i_dataset, dataset_name in enumerate(tqdm(datasets)):\n",
    "        dataset_filename = f\"{cache_path}/{dataset_name}.pickle\"\n",
    "        with open(dataset_filename, \"rb\") as f:\n",
    "            dataset_info = pickle.load(f)\n",
    "            \n",
    "        X, y = dataset_info[\"dataset\"]\n",
    "        \n",
    "        for i_algorithm, algorithm_name in enumerate(algorithms):\n",
    "            alg_name = algorithm_name.replace(\"\\\\n\", \"\\n\").replace(\"\\n\", \"\")\n",
    "            alg_filename = f\"{cache_path}/{dataset_name}_{alg_name}.pickle\"\n",
    "            if alg_filename in missing_files:\n",
    "                print(\"skipping\", alg_filename)\n",
    "                continue\n",
    "            with open(alg_filename, \"rb\") as f:\n",
    "                algorithm = pickle.load(f)\n",
    "            if hasattr(algorithm, \"labels_\"):\n",
    "                y_pred = algorithm.labels_.astype(int)\n",
    "            else:\n",
    "                if hasattr(algorithm, \"predict_with_target\"):\n",
    "                    y_pred = algorithm.predict_with_target(X, len(np.unique(y))).astype(\n",
    "                            int\n",
    "                        )\n",
    "                else:\n",
    "                    y_pred = algorithm.predict(X)\n",
    "            ari_scores[i_dataset,i_algorithm] = sklearn.metrics.adjusted_rand_score(y, y_pred)\n",
    "    df = pandas.DataFrame(ari_scores.transpose())\n",
    "    df.columns = datasets # sets names for the axes\n",
    "    df.index = algorithms\n",
    "    df_nlargest = df.style.apply(lambda x: ['background-color: yellow' if v == x.nlargest(1).iloc[0] else '' for v in x], axis=0)\n",
    "    return df_nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0721e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662772fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3c764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
